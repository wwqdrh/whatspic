{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DMVZ2ynM0OV4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import collections\n",
        "import shutil\n",
        "import time\n",
        "import glob\n",
        "import csv\n",
        "import numpy as np\n",
        "import pathlib\n",
        "\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "ROOT_DIR = os.getcwd()\n",
        "DATA_HOME_DIR = ROOT_DIR + '/data'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# paths\n",
        "data_path = DATA_HOME_DIR\n",
        "split_train_path = data_path + '/train/'\n",
        "os.makedirs(split_train_path, mode=666, exist_ok=True)\n",
        "full_train_path = data_path + '/train_full/'\n",
        "os.makedirs(full_train_path, mode=666, exist_ok=True)\n",
        "valid_path = data_path + '/valid/'\n",
        "os.makedirs(valid_path, mode=666, exist_ok=True)\n",
        "test_path = DATA_HOME_DIR + '/test/test/'\n",
        "os.makedirs(test_path, mode=666, exist_ok=True)\n",
        "saved_model_path = ROOT_DIR + '/models/'\n",
        "os.makedirs(saved_model_path, mode=666, exist_ok=True)\n",
        "submission_path = ROOT_DIR + '/submissions/'\n",
        "os.makedirs(submission_path, mode=666, exist_ok=True)\n",
        "\n",
        "# data\n",
        "batch_size = 8\n",
        "\n",
        "# model\n",
        "nb_runs = 1\n",
        "nb_aug = 3\n",
        "epochs = 5\n",
        "lr = 1e-4\n",
        "clip = 0.001\n",
        "archs = [\"resnet152\"]\n",
        "\n",
        "model_names = sorted(name for name in models.__dict__ if name.islower() and not name.startswith(\"__\"))\n",
        "best_prec1 = 0"
      ],
      "metadata": {
        "id": "vVUipH-C03pG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGD9wuYGHLi0",
        "outputId": "a9796cc4-1c0c-4bb1-c69c-a1820db7144a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_api',\n",
              " '_meta',\n",
              " '_utils',\n",
              " 'alexnet',\n",
              " 'convnext',\n",
              " 'convnext_base',\n",
              " 'convnext_large',\n",
              " 'convnext_small',\n",
              " 'convnext_tiny',\n",
              " 'densenet',\n",
              " 'densenet121',\n",
              " 'densenet161',\n",
              " 'densenet169',\n",
              " 'densenet201',\n",
              " 'detection',\n",
              " 'efficientnet',\n",
              " 'efficientnet_b0',\n",
              " 'efficientnet_b1',\n",
              " 'efficientnet_b2',\n",
              " 'efficientnet_b3',\n",
              " 'efficientnet_b4',\n",
              " 'efficientnet_b5',\n",
              " 'efficientnet_b6',\n",
              " 'efficientnet_b7',\n",
              " 'efficientnet_v2_l',\n",
              " 'efficientnet_v2_m',\n",
              " 'efficientnet_v2_s',\n",
              " 'get_model',\n",
              " 'get_model_builder',\n",
              " 'get_model_weights',\n",
              " 'get_weight',\n",
              " 'googlenet',\n",
              " 'inception',\n",
              " 'inception_v3',\n",
              " 'list_models',\n",
              " 'maxvit',\n",
              " 'maxvit_t',\n",
              " 'mnasnet',\n",
              " 'mnasnet0_5',\n",
              " 'mnasnet0_75',\n",
              " 'mnasnet1_0',\n",
              " 'mnasnet1_3',\n",
              " 'mobilenet',\n",
              " 'mobilenet_v2',\n",
              " 'mobilenet_v3_large',\n",
              " 'mobilenet_v3_small',\n",
              " 'mobilenetv2',\n",
              " 'mobilenetv3',\n",
              " 'optical_flow',\n",
              " 'quantization',\n",
              " 'regnet',\n",
              " 'regnet_x_16gf',\n",
              " 'regnet_x_1_6gf',\n",
              " 'regnet_x_32gf',\n",
              " 'regnet_x_3_2gf',\n",
              " 'regnet_x_400mf',\n",
              " 'regnet_x_800mf',\n",
              " 'regnet_x_8gf',\n",
              " 'regnet_y_128gf',\n",
              " 'regnet_y_16gf',\n",
              " 'regnet_y_1_6gf',\n",
              " 'regnet_y_32gf',\n",
              " 'regnet_y_3_2gf',\n",
              " 'regnet_y_400mf',\n",
              " 'regnet_y_800mf',\n",
              " 'regnet_y_8gf',\n",
              " 'resnet',\n",
              " 'resnet101',\n",
              " 'resnet152',\n",
              " 'resnet18',\n",
              " 'resnet34',\n",
              " 'resnet50',\n",
              " 'resnext101_32x8d',\n",
              " 'resnext101_64x4d',\n",
              " 'resnext50_32x4d',\n",
              " 'segmentation',\n",
              " 'shufflenet_v2_x0_5',\n",
              " 'shufflenet_v2_x1_0',\n",
              " 'shufflenet_v2_x1_5',\n",
              " 'shufflenet_v2_x2_0',\n",
              " 'shufflenetv2',\n",
              " 'squeezenet',\n",
              " 'squeezenet1_0',\n",
              " 'squeezenet1_1',\n",
              " 'swin_b',\n",
              " 'swin_s',\n",
              " 'swin_t',\n",
              " 'swin_transformer',\n",
              " 'swin_v2_b',\n",
              " 'swin_v2_s',\n",
              " 'swin_v2_t',\n",
              " 'vgg',\n",
              " 'vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn',\n",
              " 'video',\n",
              " 'vision_transformer',\n",
              " 'vit_b_16',\n",
              " 'vit_b_32',\n",
              " 'vit_h_14',\n",
              " 'vit_l_16',\n",
              " 'vit_l_32',\n",
              " 'wide_resnet101_2',\n",
              " 'wide_resnet50_2']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    acc = AverageMeter()\n",
        "    end = time.time()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        target = target.cuda()\n",
        "        image_var = torch.autograd.Variable(images)\n",
        "        label_var = torch.autograd.Variable(target)\n",
        "\n",
        "        # compute y_pred\n",
        "        y_pred = model(image_var)\n",
        "        loss = criterion(y_pred, label_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec1 = accuracy(y_pred.data, target, topk=(1, 1))\n",
        "        losses.update(loss.data, images.size(0))\n",
        "        acc.update(prec1, images.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()"
      ],
      "metadata": {
        "id": "rq6c5BgBHPzv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(val_loader, model, criterion, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    acc = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (images, labels) in enumerate(val_loader):\n",
        "        labels = labels.cuda()\n",
        "        image_var = torch.autograd.Variable(images)\n",
        "        label_var = torch.autograd.Variable(labels)\n",
        "\n",
        "        # compute y_pred\n",
        "        y_pred = model(image_var)\n",
        "        loss = criterion(y_pred, label_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, temp_var = accuracy(y_pred.data, labels, topk=(1, 1))\n",
        "        losses.update(loss.data, images.size(0))\n",
        "        acc.update(prec1, images.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "    print('   * EPOCH {epoch} | Accuracy: {acc.avg:.3f} | Loss: {losses.avg:.3f}'.format(epoch=epoch,\n",
        "                                                                                         acc=acc,\n",
        "                                                                                         losses=losses))\n",
        "\n",
        "    return acc.avg"
      ],
      "metadata": {
        "id": "Pu93M_eHHRb7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_loader, model):\n",
        "    csv_map = collections.defaultdict(float)\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    for aug in range(nb_aug):\n",
        "        print(\"   * Predicting on test augmentation {}\".format(aug + 1))\n",
        "\n",
        "        for i, (images, filepath) in enumerate(test_loader):\n",
        "            # pop extension, treat as id to map\n",
        "            filepath = os.path.splitext(os.path.basename(filepath[0]))[0]\n",
        "            filepath = int(filepath)\n",
        "\n",
        "            image_var = torch.autograd.Variable(images)\n",
        "            y_pred = model(image_var)\n",
        "            # get the index of the max log-probability\n",
        "            smax = nn.Softmax()\n",
        "            smax_out = smax(y_pred)[0]\n",
        "            cat_prob = smax_out.data[0]\n",
        "            dog_prob = smax_out.data[1]\n",
        "            prob = dog_prob\n",
        "            if cat_prob > dog_prob:\n",
        "                prob = 1 - cat_prob\n",
        "            prob = np.around(prob.cpu(), decimals=4)\n",
        "            prob = np.clip(prob, clip, 1-clip)\n",
        "            csv_map[filepath] += (prob / nb_aug)\n",
        "\n",
        "    sub_fn = submission_path + '{0}epoch_{1}clip_{2}runs'.format(epochs, clip, nb_runs)\n",
        "\n",
        "    for arch in archs:\n",
        "        sub_fn += \"_{}\".format(arch)\n",
        "\n",
        "    print(\"Writing Predictions to CSV...\")\n",
        "    with open(sub_fn + '.csv', 'w') as csvfile:\n",
        "        fieldnames = ['id', 'label']\n",
        "        csv_w = csv.writer(csvfile)\n",
        "        csv_w.writerow(('id', 'label'))\n",
        "        for row in sorted(csv_map.items()):\n",
        "            csv_w.writerow(row)\n",
        "    print(\"Done.\")"
      ],
      "metadata": {
        "id": "66H0ynR1HXJS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pth.tar')"
      ],
      "metadata": {
        "id": "1Mok5L4gHaSm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "aRjTuWFwHdpN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    global lr\n",
        "    lr = lr * (0.1**(epoch // 30))\n",
        "    for param_group in optimizer.state_dict()['param_groups']:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def accuracy(y_pred, y_actual, topk=(1, )):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = y_actual.size(0)\n",
        "\n",
        "    _, pred = y_pred.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(y_actual.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "m6Abyu2wHgbV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestImageFolder(data.Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        images = []\n",
        "        for filename in sorted(glob.glob(test_path + \"*.jpg\")):\n",
        "            images.append('{}'.format(filename))\n",
        "\n",
        "        self.root = root\n",
        "        self.imgs = images\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.imgs[index]\n",
        "        img = Image.open(os.path.join(self.root, filename))\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, filename\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "adEXg1x1HjGl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shear(img):\n",
        "    width, height = img.size\n",
        "    m = random.uniform(-0.05, 0.05)\n",
        "    xshift = abs(m) * width\n",
        "    new_width = width + int(round(xshift))\n",
        "    img = img.transform((new_width, height), Image.AFFINE,\n",
        "                        (1, m, -xshift if m > 0 else 0, 0, 1, 0),\n",
        "                        Image.BICUBIC)\n",
        "    return img"
      ],
      "metadata": {
        "id": "9d28UhubHl49"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(mode=\"train\", resume=False):\n",
        "\n",
        "    global best_prec1\n",
        "    print(archs)\n",
        "    for arch in archs:\n",
        "\n",
        "        # create model\n",
        "        print(\"=> Starting {0} on '{1}' model\".format(mode, arch))\n",
        "        model = models.__dict__[arch](pretrained=True)\n",
        "        # Don't update non-classifier learned features in the pretrained networks\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        # Replace the last fully-connected layer\n",
        "        # Parameters of newly constructed modules have requires_grad=True by default\n",
        "        # Final dense layer needs to replaced with the previous out chans, and number of classes\n",
        "        # in this case -- resnet 101 - it's 2048 with two classes (cats and dogs)\n",
        "        model.fc = nn.Linear(2048, 2)\n",
        "\n",
        "        if arch.startswith('alexnet') or arch.startswith('vgg'):\n",
        "            model.features = torch.nn.DataParallel(model.features)\n",
        "            model.cuda()\n",
        "        else:\n",
        "            model = torch.nn.DataParallel(model).cuda()\n",
        "\n",
        "        # optionally resume from a checkpoint\n",
        "        if resume:\n",
        "            if os.path.isfile(resume):\n",
        "                print(\"=> Loading checkpoint '{}'\".format(resume))\n",
        "                checkpoint = torch.load(resume)\n",
        "                start_epoch = checkpoint['epoch']\n",
        "                best_prec1 = checkpoint['best_prec1']\n",
        "                model.load_state_dict(checkpoint['state_dict'])\n",
        "                print(\"=> Loaded checkpoint (epoch {})\".format(checkpoint['epoch']))\n",
        "            else:\n",
        "                print(\"=> No checkpoint found at '{}'\".format(args.resume))\n",
        "\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "        # Data loading code\n",
        "        traindir = split_train_path\n",
        "        valdir = valid_path\n",
        "        testdir = test_path\n",
        "\n",
        "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "        train_loader = data.DataLoader(\n",
        "            datasets.ImageFolder(traindir,\n",
        "                                 transforms.Compose([\n",
        "                                     # transforms.Lambda(shear),\n",
        "                                     transforms.RandomResizedCrop(224),\n",
        "                                     transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     normalize,\n",
        "                                 ])),\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=4,\n",
        "            pin_memory=True)\n",
        "\n",
        "        val_loader = data.DataLoader(\n",
        "            datasets.ImageFolder(valdir,\n",
        "                                 transforms.Compose([\n",
        "                                     transforms.Resize(256),\n",
        "                                     transforms.CenterCrop(224),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     normalize,\n",
        "                                 ])),\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=4,\n",
        "            pin_memory=True)\n",
        "\n",
        "        test_loader = data.DataLoader(\n",
        "            TestImageFolder(testdir,\n",
        "                            transforms.Compose([\n",
        "                                # transforms.Lambda(shear),\n",
        "                                transforms.Resize(256),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                normalize,\n",
        "                            ])),\n",
        "            batch_size=1,\n",
        "            shuffle=False,\n",
        "            num_workers=1,\n",
        "            pin_memory=False)\n",
        "\n",
        "\n",
        "        if mode == \"test\":\n",
        "            test(test_loader, model)\n",
        "            return\n",
        "\n",
        "        # define loss function (criterion) and pptimizer\n",
        "        criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "        if mode == \"validate\":\n",
        "            validate(val_loader, model, criterion, 0)\n",
        "            return\n",
        "\n",
        "        optimizer = optim.Adam(model.module.fc.parameters(), lr, weight_decay=1e-4)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "            # train for one epoch\n",
        "            train(train_loader, model, criterion, optimizer, epoch)\n",
        "\n",
        "            # evaluate on validation set\n",
        "            prec1 = validate(val_loader, model, criterion, epoch)\n",
        "\n",
        "            # remember best Accuracy and save checkpoint\n",
        "            is_best = prec1 > best_prec1\n",
        "            best_prec1 = max(prec1, best_prec1)\n",
        "            save_checkpoint({\n",
        "                'epoch': epoch + 1,\n",
        "                'arch': arch,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'best_prec1': best_prec1,\n",
        "            }, is_best)"
      ],
      "metadata": {
        "id": "_Asn4KlwHo-n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(mode=\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "N0t80w5rHrpc",
        "outputId": "bdcf571d-2c1b-4b44-c5ae-558babd7b0d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['resnet152']\n",
            "=> Starting train on 'resnet152' model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
            "100%|██████████| 230M/230M [00:00<00:00, 270MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-277c01e2c1c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-36779b93b63d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(mode, resume)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         train_loader = data.DataLoader(\n\u001b[0;32m---> 47\u001b[0;31m             datasets.ImageFolder(traindir,\n\u001b[0m\u001b[1;32m     48\u001b[0m                                  transforms.Compose([\n\u001b[1;32m     49\u001b[0m                                      \u001b[0;31m# transforms.Lambda(shear),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes .ipynb_checkpoints, dogs. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main(mode=\"validate\", resume='model_best.pth.tar')"
      ],
      "metadata": {
        "id": "WmVLQIpLLlTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(mode=\"test\", resume='model_best.pth.tar')"
      ],
      "metadata": {
        "id": "1XQ1OmdrLnDl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}